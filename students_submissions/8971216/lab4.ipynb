{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 10)\n",
      "(66, 10)\n",
      "(67, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "X, y = datasets.load_diabetes(as_frame=True, scaled=False, return_X_y=True)\n",
    "\n",
    "# Approximately 70-15-15 split\n",
    "# split into X_train and X_test, y_train and y_test first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# further split the original \"test\" set into 2, for test and validation\n",
    "X_vali, X_test, y_vali, y_test = train_test_split(X_test, y_test, test_size= 0.5, random_state= 0)\n",
    "\n",
    "# printing the shape to check dimensions\n",
    "print(X_train.shape)\n",
    "print(X_vali.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "def model_fit(model, X_train, y_train, \\\n",
    "              X_vali, y_vali, X_test, y_test, poly=False, uni= False):\n",
    "      \n",
    "        if uni == True:\n",
    "            X_train = X_train['bmi'].values.reshape(-1,1)\n",
    "            X_vali = X_vali['bmi'].values.reshape(-1,1)\n",
    "            X_test = X_test['bmi'].values.reshape(-1,1)\n",
    "\n",
    "        if poly == True: \n",
    "           poly_transform = PolynomialFeatures(include_bias= False)\n",
    "           X_train = poly_transform.fit_transform(X_train)\n",
    "           X_vali = poly_transform.fit_transform(X_vali)\n",
    "           X_test = poly_transform.fit_transform(X_test)\n",
    "           print(len(poly_transform.get_feature_names_out()))\n",
    "           \n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_vali_pred = model.predict(X_vali)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        print('Train MAE: ' + str(mean_absolute_error(y_train, y_train_pred)))\n",
    "        print('Validation MAE: ' + str(mean_absolute_error(y_vali, y_vali_pred)))\n",
    "        print('Train MAPE: ' + \\\n",
    "              str(mean_absolute_percentage_error(y_train, y_train_pred)))\n",
    "        print('Validation MAPE: ' + \\\n",
    "              str(mean_absolute_percentage_error(y_vali, y_vali_pred)))\n",
    "        print('Train R2: ' + str(r2_score(y_train, y_train_pred)))\n",
    "        print('Validation R2: ' + str(r2_score(y_vali, y_vali_pred)))\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR\n",
      "Train MAE: 44.09783499263568\n",
      "Validation MAE: 42.31000452123342\n",
      "Train MAPE: 0.3959249325786459\n",
      "Validation MAPE: 0.35917661909863935\n",
      "Train R2: 0.5244124363545944\n",
      "Validation R2: 0.5488623329503926\n",
      "\n",
      "Univariate Polynomial\n",
      "2\n",
      "Train MAE: 51.88308912495529\n",
      "Validation MAE: 52.91980477008081\n",
      "Train MAPE: 0.48217232352802764\n",
      "Validation MAPE: 0.438735947256621\n",
      "Train R2: 0.3668374933864168\n",
      "Validation R2: 0.303586568283867\n",
      "\n",
      "Mulivariate Polynomial\n",
      "65\n",
      "Train MAE: 39.42527558975147\n",
      "Validation MAE: 41.87466058403149\n",
      "Train MAPE: 0.34999955927472565\n",
      "Validation MAPE: 0.35875678280674345\n",
      "Train R2: 0.6081125571650757\n",
      "Validation R2: 0.5351386788756555\n"
     ]
    }
   ],
   "source": [
    "print(\"MLR\")\n",
    "model_fit(LinearRegression(), X_train, y_train,\\\n",
    "           X_vali, y_vali, X_test, y_test)\n",
    "print(\"\")\n",
    "print(\"Univariate Polynomial\")\n",
    "model_fit(LinearRegression(), X_train, y_train,\\\n",
    "           X_vali, y_vali, X_test, y_test, poly= True, uni= True)\n",
    "print(\"\")\n",
    "print(\"Mulivariate Polynomial\")\n",
    "model_fit(LinearRegression(), X_train, y_train,\\\n",
    "           X_vali, y_vali, X_test, y_test, poly= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 ###\n",
    "Each metric is applied to both the training data, and the validation data. This is a way to check for overfitting. If the performance metric for the training data is much lower than the performance metric for the validation data, this is a sign that overfitting is occuring. In our case for the 3 models, there isn't a significant difference between the performance metrics for training and validation, and thus I do not think that overfitting is occuring. \n",
    "\n",
    "The MAE is the Mean Absolute Error. This can be interpreted as the the mean distance between the predicted results and the true values of the results. It has a minimum value of 0, but it has no maximum value. In the case of our 3 models here, we can see that the Multivariate Polynomial model has the lowest MAE. That means that, on average, the distance between the predicted value and the true value is the closest. It is difficult to interpret the performance of the model with this value in isolation, and as such different metrics are also usually used as performance metrics. \n",
    "\n",
    "The MAPE is the Mean Average Performance Error. This can be interpreted as the mean percentage difference between the predicted results and the true values. As it is a percentage, the value ranges between 0 and 100. Compared to MAE, this gives us some context to how our model is performing as MAPE as it is a percentage error instead of simply the mean distance. In the case of our 3 models, the MLR model and the Multivariate Polynomial models perform similarly (with Train/Validation MAPE of 0.40/0.36 and 0.35/0.36 respectively), while the Univariate Polynomial model performs poorly incomparison (0.48/0.44).\n",
    "\n",
    "The $R^2$ value can be interpreted as the proportion of the variance in the data that can be explained by the model. It is a value with a max value of 1, but no minimum value. A maximum value of 1 would mean that our independent variables perfectly explains the dependent variables. The results of our 3 models is similar to the MAPE, where the linear model and the multivariate polynomial model perform similarly, while the univariate model does not perform as well. However, even our best performing model, the linear model has a validation $R^2$ value of 0.55, which is not a very high value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 ###\n",
    "i) In the MLR model, we are fitting 11 parameters (one for each feature and one for the intercept). In the Univariate Polynomial model, we are fitting 3 parameters (1 for bmi, 1 for bmi squared, and the intercept). In the Multivariate Polynomial model, we are fitting 66 parameters (one for each feature, and one for each pairwise multiplication of the features, and the intercept).\n",
    "\n",
    "In the linear model, each coefficient represents the effect of a unit change in that independent variable on the independent variable. (e.g. if a coefficient is 0.5, that means for 1 unit increase in its associated independent variable, it increases the dependent variable by 0.5). \n",
    "\n",
    "In the polynomial models, the coefficients can be interpreted in the same manner, but the distinct pairwise multiplication of the features are now interaction terms between the two independent variables, and multiplication of the same independent variable on itself is the the variables squared.\n",
    "\n",
    "ii) I would choose between the linear model and the multivariate polynomial model. These two have very similar performance metrics, with the linear model having a slightly better $R^2$ value, and the polynomial model a slightly better MAPE value. Overall, I would pick the linear model, as it is a little more readily interpretable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
